{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "838b6cdf-19af-45af-bd8e-a7ed9a48c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization,MaxPooling2D,Activation,Input\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix , classification_report \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from tensorflow.keras.backend import clear_session\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12291885-9b2a-46d6-a407-9b4a81c7974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40cd6ce-4836-4ad0-b97a-053cdf81e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"Downloads/Emotion/train\"\n",
    "test_dir = \"Downloads/Emotion/test\"\n",
    "\n",
    "SEED = 12\n",
    "IMG_HEIGHT = 48\n",
    "IMG_WIDTH = 48\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "FINE_TUNING_EPOCHS = 20\n",
    "LR = 0.01\n",
    "NUM_CLASSES = 7\n",
    "EARLY_STOPPING_CRITERIA=3\n",
    "CLASS_LABELS  = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', \"Surprise\"]\n",
    "CLASS_LABELS_EMOJIS = [\"üëø\", \"ü§¢\" , \"üò±\" , \"üòä\" , \"üòê \", \"üòî\" , \"üò≤\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5eae8c19-feaa-409e-8d3c-276a57872271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22968 images belonging to 7 classes.\n",
      "Found 5741 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   rescale = 1./255,\n",
    "                                   validation_split = 0.2\n",
    "                                   \n",
    "                                  \n",
    "                                  )\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  validation_split = 0.2\n",
    "                            \n",
    "                                 )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = True , \n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    subset = \"training\",\n",
    "                                                    seed = 12\n",
    "                                                   )\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                         target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                         batch_size = BATCH_SIZE,\n",
    "                                                         shuffle  = True , \n",
    "                                                         color_mode = \"grayscale\",\n",
    "                                                         class_mode = \"categorical\",\n",
    "                                                         subset = \"validation\",\n",
    "                                                         seed = 12\n",
    "                                                        )\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = False , \n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    seed = 12\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e7b7f1-0a69-4541-b0cd-e5bb9cd9de22",
   "metadata": {},
   "source": [
    "# Transfert learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f2b42b-e293-46a8-aabe-ddf8d55da6ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce63fed-72ef-4015-bad8-42f9432bf849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(inputs):\n",
    "    feature_extractor = tf.keras.applications.DenseNet169(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights=\"imagenet\")(inputs)\n",
    "    \n",
    "    return feature_extractor\n",
    "\n",
    "def classifier(inputs):\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.Dropout(0.5) (x)\n",
    "    x = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"classification\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def final_model(inputs):\n",
    "    densenet_feature_extractor = feature_extractor(inputs)\n",
    "    classification_output = classifier(densenet_feature_extractor)\n",
    "    \n",
    "    return classification_output\n",
    "\n",
    "def define_compile_model():\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(IMG_HEIGHT ,IMG_WIDTH,3))\n",
    "    classification_output = final_model(inputs) \n",
    "    model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n",
    "     \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(0.1), \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29d0203-4d10-4eca-bdbf-0fcd2582474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = define_compile_model()\n",
    "clear_output()\n",
    "\n",
    "# Feezing the feature extraction layers\n",
    "model1.layers[1].trainable = False\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cc3adf4c-a4c7-465c-90c1-6370c57cecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 [==============================] - 1984s 6s/step - loss: 1.2591 - accuracy: 0.5528 - val_loss: 1.2788 - val_accuracy: 0.5429\n",
      "Epoch 7/30\n",
      "359/359 [==============================] - 1031s 3s/step - loss: 1.2226 - accuracy: 0.5668 - val_loss: 1.2122 - val_accuracy: 0.5731\n",
      "Epoch 8/30\n",
      "359/359 [==============================] - 1081s 3s/step - loss: 1.2003 - accuracy: 0.5788 - val_loss: 1.1989 - val_accuracy: 0.5715\n",
      "Epoch 9/30\n",
      "359/359 [==============================] - 1092s 3s/step - loss: 1.1715 - accuracy: 0.5936 - val_loss: 1.2363 - val_accuracy: 0.5701\n",
      "Epoch 10/30\n",
      "359/359 [==============================] - 991s 3s/step - loss: 1.1420 - accuracy: 0.6068 - val_loss: 1.1850 - val_accuracy: 0.5846\n",
      "Epoch 11/30\n",
      "359/359 [==============================] - 1664s 5s/step - loss: 1.1254 - accuracy: 0.6141 - val_loss: 1.2945 - val_accuracy: 0.5452\n",
      "Epoch 12/30\n",
      "359/359 [==============================] - 1788s 5s/step - loss: 1.1042 - accuracy: 0.6208 - val_loss: 1.1669 - val_accuracy: 0.5898\n",
      "Epoch 13/30\n",
      "359/359 [==============================] - 1112s 3s/step - loss: 1.0858 - accuracy: 0.6313 - val_loss: 1.3098 - val_accuracy: 0.5652\n",
      "Epoch 14/30\n",
      "359/359 [==============================] - 1096s 3s/step - loss: 1.0650 - accuracy: 0.6395 - val_loss: 1.1989 - val_accuracy: 0.5952\n",
      "Epoch 15/30\n",
      "359/359 [==============================] - ETA: 0s - loss: 1.0584 - accuracy: 0.6426Restoring model weights from the end of the best epoch: 12.\n",
      "359/359 [==============================] - 1029s 3s/step - loss: 1.0584 - accuracy: 0.6426 - val_loss: 1.1772 - val_accuracy: 0.5858\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                         patience=EARLY_STOPPING_CRITERIA,\n",
    "                                                         verbose= 1 ,\n",
    "                                                         restore_best_weights=True\n",
    "                                                        )\n",
    "history1 = model1.fit(x = train_generator,\n",
    "                    epochs = EPOCHS ,\n",
    "                    validation_data = validation_generator , \n",
    "                    callbacks= [earlyStoppingCallback])\n",
    "\n",
    "history1 = pd.DataFrame(history1.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f1632496-3cf9-464e-b18c-c1700283a3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "359/359 [==============================] - 1121s 3s/step - loss: 1.0487 - accuracy: 0.6434 - val_loss: 1.0752 - val_accuracy: 0.6248\n",
      "Epoch 2/20\n",
      "359/359 [==============================] - 1110s 3s/step - loss: 1.0076 - accuracy: 0.6594 - val_loss: 1.0620 - val_accuracy: 0.6319\n",
      "Epoch 3/20\n",
      "359/359 [==============================] - 1085s 3s/step - loss: 0.9945 - accuracy: 0.6627 - val_loss: 1.0554 - val_accuracy: 0.6351\n",
      "Epoch 4/20\n",
      "359/359 [==============================] - 1123s 3s/step - loss: 0.9874 - accuracy: 0.6649 - val_loss: 1.0516 - val_accuracy: 0.6340\n",
      "Epoch 5/20\n",
      "359/359 [==============================] - 1156s 3s/step - loss: 0.9763 - accuracy: 0.6719 - val_loss: 1.0475 - val_accuracy: 0.6379\n",
      "Epoch 6/20\n",
      "359/359 [==============================] - 1143s 3s/step - loss: 0.9682 - accuracy: 0.6706 - val_loss: 1.0452 - val_accuracy: 0.6384\n",
      "Epoch 7/20\n",
      "359/359 [==============================] - 1110s 3s/step - loss: 0.9574 - accuracy: 0.6742 - val_loss: 1.0430 - val_accuracy: 0.6422\n",
      "Epoch 8/20\n",
      "359/359 [==============================] - 1107s 3s/step - loss: 0.9521 - accuracy: 0.6784 - val_loss: 1.0409 - val_accuracy: 0.6419\n",
      "Epoch 9/20\n",
      "359/359 [==============================] - 1082s 3s/step - loss: 0.9521 - accuracy: 0.6775 - val_loss: 1.0379 - val_accuracy: 0.6420\n",
      "Epoch 10/20\n",
      "359/359 [==============================] - 1165s 3s/step - loss: 0.9431 - accuracy: 0.6802 - val_loss: 1.0362 - val_accuracy: 0.6436\n",
      "Epoch 11/20\n",
      "359/359 [==============================] - 1142s 3s/step - loss: 0.9455 - accuracy: 0.6834 - val_loss: 1.0343 - val_accuracy: 0.6429\n",
      "Epoch 12/20\n",
      "359/359 [==============================] - 1947s 5s/step - loss: 0.9384 - accuracy: 0.6798 - val_loss: 1.0324 - val_accuracy: 0.6407\n",
      "Epoch 13/20\n",
      "359/359 [==============================] - 2575s 7s/step - loss: 0.9341 - accuracy: 0.6814 - val_loss: 1.0331 - val_accuracy: 0.6417\n",
      "Epoch 14/20\n",
      "359/359 [==============================] - 2450s 7s/step - loss: 0.9314 - accuracy: 0.6838 - val_loss: 1.0318 - val_accuracy: 0.6417\n",
      "Epoch 15/20\n",
      "359/359 [==============================] - 1679s 5s/step - loss: 0.9245 - accuracy: 0.6874 - val_loss: 1.0316 - val_accuracy: 0.6427\n",
      "Epoch 16/20\n",
      "359/359 [==============================] - 1184s 3s/step - loss: 0.9209 - accuracy: 0.6855 - val_loss: 1.0304 - val_accuracy: 0.6431\n",
      "Epoch 17/20\n",
      "359/359 [==============================] - 1124s 3s/step - loss: 0.9189 - accuracy: 0.6869 - val_loss: 1.0284 - val_accuracy: 0.6436\n",
      "Epoch 18/20\n",
      "359/359 [==============================] - 1155s 3s/step - loss: 0.9113 - accuracy: 0.6923 - val_loss: 1.0300 - val_accuracy: 0.6443\n",
      "Epoch 19/20\n",
      "359/359 [==============================] - 1150s 3s/step - loss: 0.9098 - accuracy: 0.6920 - val_loss: 1.0273 - val_accuracy: 0.6445\n",
      "Epoch 20/20\n",
      "359/359 [==============================] - 1129s 3s/step - loss: 0.9126 - accuracy: 0.6911 - val_loss: 1.0258 - val_accuracy: 0.6455\n"
     ]
    }
   ],
   "source": [
    "# Un-Freezing the feature extraction layers for fine tuning \n",
    "model1.layers[1].trainable = True\n",
    "\n",
    "model1.compile(optimizer=tf.keras.optimizers.SGD(0.001), #lower learning rate\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "history_ = model1.fit(x = train_generator,epochs = FINE_TUNING_EPOCHS ,validation_data = validation_generator)\n",
    "history1 = history1.append(pd.DataFrame(history_.history) , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e43327ad-d25c-4214-97c6-5e36ec06aa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 111s 981ms/step - loss: 1.0382 - accuracy: 0.6415\n",
      "113/113 [==============================] - 127s 1s/step\n"
     ]
    }
   ],
   "source": [
    "model1.save(\"model_TL.h5\")\n",
    "model1.evaluate(test_generator)\n",
    "preds1 = model1.predict(test_generator)\n",
    "y_preds1 = np.argmax(preds1 , axis = 1 )\n",
    "y_test = np.array(test_generator.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e985ba0c-3aca-474a-8c0e-acd3aac0d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'y_pred': y_preds1\n",
    "})\n",
    "data1.to_csv('data_evaluation1.csv', index=False)\n",
    "history1.to_csv('training1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
